{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "CHECKPOINT_PATH = \"/home/featurize/work/checkpoint_2_kendall_tau=0.7809.pt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import sys\n",
    "state = torch.load(CHECKPOINT_PATH)\n",
    "sys.path.insert(0, f\"/home/featurize/work/ai4code/_runs/{state['params']['git_commits']}\")\n",
    "from ai4code import models, datasets, metrics, utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'ai4code.metrics' from '/home/featurize/work/ai4code/_runs/17aced5895ad01ad44c2959df1804cb9226eadaf/ai4code/metrics.py'>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = state['params']\n",
    "dataset_suffix = params['dataset_suffix']\n",
    "val_folds = params['val_folds']\n",
    "val_num_samples = params['val_num_samples']\n",
    "pretrained_path = params['pretrained_path']\n",
    "extra_vocab = params['extra_vocab']\n",
    "cell_token_size = params['cell_token_size']\n",
    "cell_stride = params['cell_stride']\n",
    "context_cells_token_size = params['context_cells_token_size']\n",
    "context_stride = params['context_stride']\n",
    "max_len = params['max_len']\n",
    "num_workers = params['num_workers']\n",
    "batch_size = params['batch_size']\n",
    "dropout = params['dropout']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "from transformers import AutoTokenizer\n",
    "from torch.utils.data import DataLoader\n",
    "from ignite.engine import Engine, Events\n",
    "from ignite.contrib.handlers import ProgressBar\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pickle.load(open(f\"/home/featurize/work/ai4code/data/fold0.{params['dataset_suffix']}.pkl\", \"rb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_num_samples = None\n",
    "val_data = {k: v for k, v in list(data.items()) if v.fold in val_folds}\n",
    "if val_num_samples is not None:\n",
    "    val_data = {k: v for k, v in list(val_data.items())[:val_num_samples]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(\n",
    "    pretrained_path, do_lower_case=True, use_fast=True\n",
    ")\n",
    "if extra_vocab:\n",
    "    extra_vocab = pickle.load(open(extra_vocab, \"rb\"))\n",
    "    tokenizer.add_tokens(x[0] for x in extra_vocab.most_common(2000))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_dataset(data):\n",
    "    return datasets.RankDataset(\n",
    "        data,\n",
    "        tokenizer=tokenizer,\n",
    "        cell_token_size=cell_token_size,\n",
    "        cell_stride=cell_stride,\n",
    "        context_cells_token_size=context_cells_token_size,\n",
    "        context_stride=context_stride,\n",
    "        max_len=max_len,\n",
    "    )\n",
    "\n",
    "val_loader = DataLoader(\n",
    "    create_dataset(val_data),\n",
    "    num_workers=num_workers,\n",
    "    batch_size=batch_size,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at /home/featurize/distilbert-base-uncased/distilbert-base-uncased were not used when initializing DistilBertModel: ['vocab_transform.bias', 'vocab_projector.weight', 'vocab_transform.weight', 'vocab_projector.bias', 'vocab_layer_norm.weight', 'vocab_layer_norm.bias']\n",
      "- This IS expected if you are initializing DistilBertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing DistilBertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "source": [
    "model = models.Model(pretrained_path, dropout)\n",
    "if extra_vocab:\n",
    "    model.backbone.resize_token_embeddings(len(tokenizer))\n",
    "model.to(\"cuda\")\n",
    "model.eval()\n",
    "model.load_state_dict(state['model'])\n",
    "criterion = torch.nn.L1Loss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "@torch.no_grad()\n",
    "def rank_eval(engine, batch):\n",
    "    model.eval()\n",
    "    ids, mask, targets, cell_numbers = [item.to('cuda') for item in batch[:4]]\n",
    "    sample_ids, cell_keys = batch[4:]\n",
    "    scores = model(ids, mask, cell_numbers)\n",
    "    loss = criterion(scores, targets).item()\n",
    "    return loss, scores, sample_ids, cell_keys\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluator = Engine(rank_eval)\n",
    "ProgressBar().attach(evaluator)\n",
    "metric = metrics.KendallTauNaive(val_data)\n",
    "metric.attach(evaluator, \"kendall_tau\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dbf0fb688b444ed08d5264cf2d76a42a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "[1/1707]   0%|           [00:00<?]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "Kendall Tau:  0.7791757177483314\n"
     ]
    }
   ],
   "source": [
    "_ = evaluator.run(val_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_scores = {}\n",
    "\n",
    "for sample_id, preds in metric._submission_data.items():\n",
    "    sample = val_data[sample_id]\n",
    "    targets = sample.orders\n",
    "    sample_scores[sample_id] = metrics.kendall_tau([targets], [preds])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "_ = plt.hist(sample_scores.values(), bins=np.arange(0, 1, 0.02))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "key:  69820fe579379e  score:  0.42690058479532167\n"
     ]
    }
   ],
   "source": [
    "candinates = {k: v for k, v in sample_scores.items() if v < 0.7}.keys()\n",
    "key_id = random.sample(candinates, k=1)[0]\n",
    "sample = val_data[key_id]\n",
    "print(\"key: \", key_id, \" score: \", sample_scores[key_id])\n",
    "content_targets = \"\"\n",
    "content_preds = \"\"\n",
    "sources = \"\"\n",
    "wrong_sources = \"\"\n",
    "\n",
    "for key in sample.orders:\n",
    "    content_targets += f\"{key}\\t{sample.cell_types[key]}\\n\"\n",
    "\n",
    "    sources += \">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>> \" + sample.cell_types[key] + \"\\n\"\n",
    "    sources += sample.sources[key] + \"\\n\\n\\n\"\n",
    "\n",
    "for key in metric._submission_data[sample.id]:\n",
    "    content_preds += f\"{key}\\t{sample.cell_types[key]}\\n\"\n",
    "\n",
    "    wrong_sources += \">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>> \" + sample.cell_types[key] + \"\\n\"\n",
    "    wrong_sources += sample.sources[key] + \"\\n\\n\\n\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4520"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "open(\"/tmp/1\", \"w\").write(content_targets)\n",
    "open(\"/tmp/2\", \"w\").write(content_preds)\n",
    "open(\"/tmp/source\", \"w\").write(sources)\n",
    "open(\"/tmp/wrong_source\", \"w\").write(wrong_sources)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    }
   ],
   "source": [
    "!diff -y /tmp/1 /tmp/2 > /tmp/3"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "b114295533213be714c497b6c7c7c36862ca698da8b4418201631177dea05d47"
  },
  "kernelspec": {
   "display_name": "Python 3.7.10 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
